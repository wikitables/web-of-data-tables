
from nltk import ngrams


def vectorize(inputFile):
    # Save header as vector of numbers
    output_file = "vect.txt"
    # Safe dictionary of numbers with respective header.
    dict_file = "dict.txt"

    dictf = open(dict_file, "w")
    out = open(output_file, "w")

    dict = {}
    count = 0
    with open(inputFile, "r", encoding="utf-8") as inFile:
        cont = 0
        for line in inFile:
            print("line:", cont)
            cont += 1
            l=line.replace("\n", "").split("\t")
            number=l[3]
            l = l[5]
            words = l.split(",")
            for w in words:
                sw=w.strip()
                if dict.get(sw) == None and sw != "":
                    dict[sw] = count
                    count += 1
            setvec = []
            for w in words:
                sw = w.strip()
                setvec.append(dict.get(sw))

            setvec.sort()
            out.write(str(number)+"\t"+str(setvec) + "\n")
    for k, v in dict.items():
        dictf.write(str(v) + "\t" + str(k) + "\n")
    out.close()
    dictf.close()

def generateNgrams(ngram, nameVectFile):
    """
    :param ngram: quantity of headers to build the ngram
    :param nameVectFile: file with list of vectors generated in vectorize method
    :return:
    """

    # List of ngrams
    output_file = "ngram_list.txt"  # sys.argv[2]
    # Dictionary by vector
    ngram_dict="ngram_dict.txt"
    fo = open(output_file, "w")
    fodict=open(ngram_dict,"w")
    with open(nameVectFile, "r") as vectFile:
        for line in vectFile:
            sentence=line.replace("\n","").split("\t")
            number=sentence[0]
            sentence=sentence[1]
            sentence=eval(sentence)
            grams = ngrams(sentence, ngram)
            grams=list(grams)
            dict_g={}
            for g in grams:
                dict_g[str(list(g))]=number
                fo.write(str(list(g))+"\n")
            fodict.write(str(dict_g)+"\n")
    fo.close()
    fodict.close()


def fiterNgrams(nameNgramsFile, filter):
    """
    :param nameNgramsFile: File with list of ngrams generated by generateNgrams
    :param filter: True for deleting ngrams with one ocurrence, false in otherwise.
    :return:
    """

    # File with filter ngrams and number of ocurrences
    output_file = "ngram_list_filtered.txt"
    uniq_gram = {}
    more_one = {}
    cont=0
    if filter:
        with open(nameNgramsFile, "r") as file:
            for line in file:
                l=line.replace("\n","")
                print("cont:", cont)
                if more_one.get(l)==None:
                    if uniq_gram.get(l)==None:
                        uniq_gram[l]=1
                    else:
                        more_one[l]=2
                        uniq_gram.pop(l)
                else:
                    cont += 1
                    more_one[l]=more_one[l]+1
    else:
        with open(nameNgramsFile, "r") as file:
            for line in file:
                l = line.replace("\n", "")
                print("cont:", cont)
                if more_one.get(l) == None:
                    more_one[l] = 1
                else:
                    more_one[l] = more_one[l] + 1
                cont+=1

    fo = open(output_file, "w")
    for k,v in more_one.items():
        fo.write(str(k) +"\t" +str(v)+ "\n")
    fo.close()

def cluster_tables(gramsListFile, dictGramFile, tablesFile):
    """
    :param gramsListFile: List of filtered list of ngrams
    :param dictGramFile: Dictionary by vector generated by generateNgrams
    :param tablesFile: Main file with list of tables and headers.
    :return:
    """
    file_gram = open(gramsListFile, "r")
    lines = file_gram.readlines()
    dict_gram = {}
    gram_count={}
    for i, line in enumerate(lines):
        word = line.replace("\n", "").split("\t")
        print("line:", i)
        dict_gram[str(word[0])] = []
        gram_count[str(word[0])] =int(word[1])
    lines.clear()
    file_gram.close()

    with open(dictGramFile, "r") as file:
        count = 0
        for line in file:
            print("count:", count)
            dict_line = eval(line)
            k_grams=dict_line.keys()

            # Getting the most frequent ngram by vector (table)
            # Each ngram most frequent will be a  "cluster".
            frequentg=max_gram(list(k_grams), gram_count)
            if frequentg!=None:
                values=dict_line.values()
                value=list(values)[0]
                if dict_gram.get(str(frequentg)) != None:
                    dict_gram[str(frequentg)].append(value)
                count += 1

    # Getting tables by id_table
    tf=open(tablesFile, "r", encoding="utf-8")
    linestf=tf.readlines()
    dict_tables={}
    for line in linestf:
        ls=line.split("\t")
        dict_tables[ls[3]]=line

    # Getting header values from dict.txt
    dict_vocab=getDict()

    # Generating output file adding the ngram cluster to each table on list.
    cluster_file="cluster_file_c.csv"
    fo=open(cluster_file, "w", encoding="utf-8")
    for k, v in dict_gram.items():
        for idx in v:
            table = dict_tables[idx]
            ks = [dict_vocab.get(str(ki)) for ki in eval(k)]
            ks.sort()
            fo.write(str(ks) + "\t" + str(len(v)) + "\t" + str(idx) + "\t" + table)
    fo.close()

def max_gram(list_grams, pair_count):
    dict_gram={}
    for g in list_grams:
        if pair_count.get(str(g))!=None:
            dict_gram[str(g)]=pair_count.get(str(g))
    if len(dict_gram.items())>0:
        sorted_by_value = sorted(dict_gram.items(), key=lambda kv: kv[1])
        v=sorted_by_value[len(sorted_by_value)-1]
        v=v[0]
        return v

def getDict():
    dict_file = "dict_c.txt"
    dictf = open(dict_file, "r")
    lines = dictf.readlines()
    dict_vocab = {}
    for line in lines:
        word = line.replace("\n", "").split("\t")
        dict_vocab[str(word[0])] = word[1]
    dictf.close()
    return dict_vocab


ifile = ""
vectorize(ifile)
generateNgrams(2, "vect.txt")
fiterNgrams("ngram_list.txt", False)
cluster_tables("ngram_list_filtered.txt", "ngram_dict.txt", ifile)